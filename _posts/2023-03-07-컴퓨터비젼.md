---
layout: post
title: 컴퓨터비젼 - Binary Image Analysis
subtitle: 김창수 교수님의 Binary Image Analysis 내용 정리
gh-repo: daattali/beautiful-jekyll
gh-badge: 
tags: [Computer Vision]
comments: true
---
_written since 230307~230311 _

## Binary Image  

 Binary Image **B** 는 두 가지의 색깔로 이루어진 이미지를 의미하는데 보통 Black(1) 과 White(0) 를 사용한다. **B** 의 row 와 column 을 고려하여 **B**[r,c]의 binary value 를 따져 White 는 0의 값으로 Background(배경)를 뜻하며 Black 이 1로 Foreground 를 구성하게 된다. 

![image](https://user-images.githubusercontent.com/32359257/223438270-424d89b6-06b5-4cee-96ed-f71e51fc3661.png)

 위의 사진에서는 **B**[0,0] = 0 의 값을 가지며 흰색 pixel 을 가지게 되지만 **B**[1,1] = 1 의 값을 가져 검은색 pixel 을 가지게 된다.  

## Masking
 Masking은 사실 convolution과 동일한 연산을 image에서 하는 것이다. Mask를 적용하고자 하는 input image의 각 픽셀에 대해 mask를 적용해 이를 output image의 동일한 위치의 픽셀에 결과값을 저장하면 된다. 이 때, Mask는 보통 Normalize 되어 Input 과 Output 간의 평균값 차이 발생을 방지한다.  
![image](https://user-images.githubusercontent.com/32359257/223449857-837803af-2d8f-4a8f-aaed-665277f9ce22.png)  
위의 예시에서 노란색 위치의 Input 에 대해 Normalize 된 Mask 를 적용하면 Output의 동일한 위치에 있는 pixel에 800/16 = 50 의 결과값이 저장되게 된다. 이렇게 모든 Input에 대해 적용하는 것이 Masking 이다. 그러나 Input의 제일 첫 번째 픽셀의 경우에는 Mask하기 위해 특정 pixel들의 값을 가져오기 어려운 경우가 있는데 이럴 경우 zero-padding을 활용하면 된다.
 
## Counting Objects in an Image  
 사람은 사진을 봤을 때 사물로 인식하는 것이 크게 어렵지 않다. 그러나 컴퓨터의 입장에서는 굉장히 어려운 작업이다. 따라서 다음과 같은 방법들을 사용해 컴퓨터에게 사물을 인식할 수 있도록 한다.  
#### Corner Patterns
 2X2 Masking을 특정 패턴들을 활용해 구별하는 방법이다. 
![image](https://user-images.githubusercontent.com/32359257/223445427-646f7c37-a62b-45e4-92c5-40df86ef7576.png)  
![image](https://user-images.githubusercontent.com/32359257/223445798-94e3a5df-dd9f-47f2-b24f-84c19f45d23b.png)  
 위 두 개의 패턴들을 대입하여 # of objects = (External patterns - Internal patterns)/4 로 구하면 된다. 이의 증명은 귀납법을 활용해 소개해주셨었다. (필력이 부족하여 자세한 설명이 되지 않는 점 미리 양해를 구한다)
 검은 픽셀의 개수를 n이라고 하였을 때 n =1 일 때는 위 공식이 정상적으로 적용됨을 알 수 있다. 만약 n=k일 때 성립함을 가정하고 n=k+1 인 경우에 대해 공식이 성립하는지 보면 증명이 될 것이다. n=k+1인 경우는 n=k인 경우에서 단 1개가 추가된 경우인데 이 때 추가된 pixel의 좌표를 (0,0)으로 잡고 생각해보자. (0,0)을 기준으로 주변 8칸에 대해서만 생각하면 되므로 즉, 3X3 에서 pattern을 살펴보자! (0,0)이 추가될 검은 pixel이고 N은 기존의 3X3 구역 내 존재하는 검은 pixel들이라고 하자.
##### N=1, 2, 3
![image](https://user-images.githubusercontent.com/32359257/223446503-aac8ac5f-d526-4c07-b884-5789263c98d3.png)  
##### N=3, 4, 5
![image](https://user-images.githubusercontent.com/32359257/223446556-836aa89b-3ffd-4f05-9c9f-f1bd9aeae2e1.png)  
##### N=5, 6, 7
![image](https://user-images.githubusercontent.com/32359257/223446611-032129d0-2435-45e9-bf7f-0201c8433fdd.png)  

(회전, 대칭 경우 모두 고려하였다)  
(0,0)이 추가되기 전과 후를 비교하여서 E와 I 값이 변하는 것을 구했을 때 모든 경우에 대해서 변화량이 동일하다는 것을 알 수 있다. 즉, # of objects의 값이 변하지 않는다는 결론을 확인할 수 있다.  
 그러나 해당 방법에는 단점들이 존재한다.
 ![image](https://user-images.githubusercontent.com/32359257/223454246-c64f2559-b81e-4c38-9165-d74421990181.png) 
위 사진의 두 경우와 같이 꼭지점(vertex)를 공유하거나 hole이 존재하는 경우에는 위 방법을 사용하기 어렵다.

## Neighborhoods
![image](https://user-images.githubusercontent.com/32359257/223455492-4a739baf-0edb-42f1-91ea-24cb10c6351d.png)

## Connectedness
그렇다면 사람은 사진을 봤을 때 물체를 인지하기 쉽지만 컴퓨터는 이를 어떻게 코딩 측면에서 인식을 할까? 에 대한 답이 Connectedness 이다. Object를 정의하기 위해서 픽셀들의 집합에서 아무 2개의 element 사이가 이어지는 path(sequence)가 존재하면 이를 connected component 즉 물체라고 말한다. 
![image](https://user-images.githubusercontent.com/32359257/224475166-c9902968-6e29-473d-8221-147b424abd1e.png)
위 사진에서처럼 1번 pixel에서 5번 pixel까지 가기 위해서 1-> 2-> 3-> 4-> 5 라는 path가 존재한다면 하나의 object라고 말할 수 있다. 그리고 path는 유일하지 않을 수 있으며 Neightborhoods의 종류에 따라 path가 달라질 수 있다.
![image](https://user-images.githubusercontent.com/32359257/224475280-433bdd2e-4751-4b96-a13a-0a05fb3f7d77.png)
위 사진에서 4-Neighborhoods로 생각하면 A -> H 로 가는 path는 존재하지만 A -> K 로 가는 path는 존재하지 않는다. 즉, {A, B, C, D, E, F, G, H}는 connected components라고 말할 수 있다. 하지만 8-Neighborhoods로 생각하면 A -> K 로 가는 path가 존재하므로 {A, B, C, D, E, F, G, H} 에서 I, J, K, L 까지 추가하였을 때 connected components라고 말할 수 있을 것이다.
![image](https://user-images.githubusercontent.com/32359257/224475397-1c0d43cf-a984-4cf0-a983-9bd238f9c853.png)

이를 코딩하려면 background = 0 으로 같은 connected components끼리는 같은 숫자로 Label해야할 것이다. 하나의 예시로 Recursive Labeling 알고리즘 형식으로 구현이 가능하다.
![image](https://user-images.githubusercontent.com/32359257/224475504-4d667790-068b-4169-bfa6-41a3cfed0e05.png)

그림판으로 직접 만든 임의의 이미지 (단 저장시 단색 비트맵 bmp 형식으로 저장하면 white = True, black = False 로 저장됨)  
![image](https://user-images.githubusercontent.com/32359257/224478144-7ffbe502-339a-4116-b31a-23c5e3ddc93d.png)
를  
![image](https://user-images.githubusercontent.com/32359257/224478205-285e0676-1e7c-4896-b062-85ef490b138e.png)
이런 결과롤 나타낼 수 있었다.
코드는 다음과 같이 짰다.
```python
# Recursive Labeling for connected components of binary image by 김재웅
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image

img = Image.open('RecursiveLabeling_ex.bmp')
x = np.array(img)

def Binarize(comp):
    # White = True -> Background
    if comp == True:
        return 0
    # Black = False -> Foreground
    else:
        return -1

func = np.vectorize(Binarize)
binarzed_x = func(x)
row = binarzed_x.shape[0]
column = binarzed_x.shape[1]

def search4N(arr, r, c, label):
    arr[r,c] = label
    # Top : r-1, c
    if arr[r-1,c] == -1:
        search4N(arr,r-1,c,label)
    # Left : r, c-1
    if arr[r,c-1] == -1:
        search4N(arr,r,c-1,label)
    # Right : r, c+1
    if arr[r,c+1] == -1:
        search4N(arr,r,c+1,label)
    # Bottom : r+1, c+1
    if arr[r+1,c] == -1:
        search4N(arr,r+1,c+1,label)
    
label = 1

for r in range(0,row):
    for c in range(0,column):
        if binarzed_x[r,c] == -1:
            search4N(binarzed_x,r,c,label)
            label+=1

plt.matshow(binarzed_x)
plt.colorbar(shrink = 0.8)
plt.clim(0,label+1)
plt.show()

```

![image](https://user-images.githubusercontent.com/32359257/224478702-4905ceda-4d5d-4a2b-9923-6f7b23501f73.png)
하지만 4-Neighborhoods로 구현한 만큼 대각으로 접한 것들은 다른 object로 인식하는 것을 확인할 수 있다.
